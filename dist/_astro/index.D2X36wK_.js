import{s as d,g as l}from"./_astro_assets.CDFu4n8r.js";import{c as g,r as h,m as f,u as b}from"./hoisted.CCtZBuQU.js";import"./astro/assets-service.Bu9dkybA.js";const m={src:"/_astro/question.C4n4xyLH.png",width:483,height:553,format:"png"},x={src:"/_astro/pngchecker.Bj8GwY4s.png",width:561,height:100,format:"png"},u={src:"/_astro/restored.D8Nqn219.png",width:1920,height:1080,format:"png"},_={src:"/_astro/login.C8rI4CJP.png",width:378,height:472,format:"png"},y={src:"/_astro/cyberstealprofiile.Ci2fFgDc.png",width:1561,height:823,format:"png"},w={src:"/_astro/infostealerposted.Bw6rEp4w.png",width:1920,height:981,format:"png"},k={src:"/_astro/infostealervid.DXNwlSn0.png",width:670,height:653,format:"png"},v={src:"/_astro/infopic.BM0iuDxh.png",width:1548,height:766,format:"png"},A={src:"/_astro/cat.BAUEqhp1.jpg",width:768,height:432,format:"jpg"},I={src:"/_astro/exifcat.DhzIJ5PR.png",width:733,height:420,format:"png"},R={src:"/_astro/first.D42fyZ31.png",width:953,height:551,format:"png"},E={src:"/_astro/wayback.CMN4U3K5.png",width:951,height:505,format:"png"},G={src:"/_astro/waybackflag.C94webAU.png",width:959,height:726,format:"png"},T=async function(r){const p={};{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/question\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/question.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:m,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/pngchecker\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/pngchecker.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:x,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./files/restored\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./files/restored.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:u,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/login\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/login.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:_,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/cyberstealprofiile\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/cyberstealprofiile.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:y,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/infostealerposted\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/infostealerposted.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:w,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/infostealervid\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/infostealervid.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:k,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/infopic\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/infopic.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:v,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./files/pictures/cat\\.jpg[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./files/pictures/cat.jpg_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:A,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/exifcat\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/exifcat.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:I,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/first\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/first.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:R,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/wayback\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/wayback.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:E,...i}),n++}}{const a=new RegExp('__ASTRO_IMAGE_="([^"]*\\./img/waybackflag\\.png[^"]*)"',"g");let e,n=0;for(;(e=a.exec(r))!==null;){const s="./img/waybackflag.png_"+n,t=JSON.parse(e[1].replace(/&#x22;/g,'"')),{src:o,...i}=t;p[s]=await l({src:G,...i}),n++}}return p};async function S(r){return T(r).then(p=>r.replaceAll(/__ASTRO_IMAGE_="([^"]+)"/gm,(a,e)=>{const n=JSON.parse(e.replace(/&#x22;/g,'"')),s=n.src+"_"+n.index;p[s].srcSet&&p[s].srcSet.values.length>0&&(p[s].attributes.srcset=p[s].srcSet.attribute);const{index:t,...o}=p[s].attributes;return d({src:p[s].src,...o})}))}const c=await S(`<h2 id="forensics">Forensics<a class="anchor" href="#forensics">#</a></h2>
<hr>
<h2 id="apocalypse">Apocalypse<a class="anchor" href="#apocalypse">#</a></h2>
<p><img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/question.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"></p>
<h3 id="description">Description<a class="anchor" href="#description">#</a></h3>
<p>Notorious hacker CyberSteal6969 has struck again, this time targeting CyberX, stealing a highly confidential flag. Our team managed to seize his personal computer, but the system was wiped clean, except for a single, suspicious image left behind.</p>
<p>Reports suggest CyberSteal6969 may have been communicating with his counterpart using morse code from video. But leave no stone unturned. Can you uncover the secrets within and retrieve the stolen flag?</p>
<hr>
<h4 id="goals">Goals<a class="anchor" href="#goals">#</a></h4>
<ol>
<li>Use pngchecker to check the status of the given image, obtained ERROR:“additional data after IEND chunk”, which is after the cropped image</li>
<li>Use Acropalypse-Multi-Tool to recover the full image
<a href="https://www.youtube.com/watch?v=R866SnJoKQg" rel="nofollow, noopener, noreferrer" target="_blank">https://www.youtube.com/watch?v=R866SnJoKQg<span> ↗</span></a></li>
<li>Login to flickr with the credentials given</li>
<li>Try to find some useful informations across profile</li>
<li>Grab the pictures and analyse the metadata</li>
<li>Use wayback machine to track past version across the sites</li>
</ol>
<hr>
<h4 id="steps">Steps<a class="anchor" href="#steps">#</a></h4>
<ol>
<li>pngchecker analyse the image<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/pngchecker.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"></li>
<li>Use the script to recover the full image</li>
</ol>
<div class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><pre><code><span class="line"><span>import zlib</span></span>
<span class="line"><span>import io</span></span>
<span class="line"><span>import struct</span></span>
<span class="line"><span>import tempfile</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span></span></span>
<span class="line"><span>class Acropalypse():</span></span>
<span class="line"><span>    def parse_png_chunk(self, stream):</span></span>
<span class="line"><span>        size = int.from_bytes(stream.read(4), "big")</span></span>
<span class="line"><span>        ctype = stream.read(4)</span></span>
<span class="line"><span>        body = stream.read(size)</span></span>
<span class="line"><span>        csum = int.from_bytes(stream.read(4), "big")</span></span>
<span class="line"><span>        assert(zlib.crc32(ctype + body) == csum)</span></span>
<span class="line"><span>        return ctype, body</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def pack_png_chunk(self, stream, name, body):</span></span>
<span class="line"><span>        stream.write(len(body).to_bytes(4, "big"))</span></span>
<span class="line"><span>        stream.write(name)</span></span>
<span class="line"><span>        stream.write(body)</span></span>
<span class="line"><span>        crc = zlib.crc32(body, zlib.crc32(name))</span></span>
<span class="line"><span>        stream.write(crc.to_bytes(4, "big"))</span></span>
<span class="line"><span>        </span></span>
<span class="line"><span>    def reconstruct_image(self, cropped_image_file, img_width, img_height, rgb_alpha):</span></span>
<span class="line"><span>        PNG_MAGIC = b"\\x89PNG\\r\\n\\x1a\\n"</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        orig_width = img_width</span></span>
<span class="line"><span>        orig_height = img_height</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        with open(cropped_image_file, "rb") as f_in:</span></span>
<span class="line"><span>            magic = f_in.read(len(PNG_MAGIC))</span></span>
<span class="line"><span>            assert magic == PNG_MAGIC</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # find end of cropped PNG</span></span>
<span class="line"><span>            while True:</span></span>
<span class="line"><span>                ctype, body = self.parse_png_chunk(f_in)</span></span>
<span class="line"><span>                if ctype == b"IEND":</span></span>
<span class="line"><span>                    break</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # grab the trailing data</span></span>
<span class="line"><span>            trailer = f_in.read()</span></span>
<span class="line"><span>            </span></span>
<span class="line"><span>            print(f"Found {len(trailer)} trailing bytes!")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # find the start of the next idat chunk</span></span>
<span class="line"><span>            try:</span></span>
<span class="line"><span>                next_idat = trailer.index(b"IDAT", 12)</span></span>
<span class="line"><span>            except ValueError:</span></span>
<span class="line"><span>                raise Exception("No trailing IDATs found!")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # skip first 12 bytes in case they were part of a chunk boundary</span></span>
<span class="line"><span>            idat = trailer[12:next_idat-8] # last 8 bytes are crc32, next chunk len</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            stream = io.BytesIO(trailer[next_idat-4:])</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            while True:</span></span>
<span class="line"><span>                ctype, body = self.parse_png_chunk(stream)</span></span>
<span class="line"><span>                if ctype == b"IDAT":</span></span>
<span class="line"><span>                    idat += body</span></span>
<span class="line"><span>                elif ctype == b"IEND":</span></span>
<span class="line"><span>                    break</span></span>
<span class="line"><span>                else:</span></span>
<span class="line"><span>                    raise Exception("Unexpected chunk type: " + repr(ctype))</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            idat = idat[:-4] # slice off the adler32</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print(f"Extracted {len(idat)} bytes of idat!")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print("Building bitstream...")</span></span>
<span class="line"><span>            bitstream = []</span></span>
<span class="line"><span>            for byte in idat:</span></span>
<span class="line"><span>                for bit in range(8):</span></span>
<span class="line"><span>                    bitstream.append((byte >> bit) &#x26; 1)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # add some padding so we don't lose any bits</span></span>
<span class="line"><span>            for _ in range(7):</span></span>
<span class="line"><span>                bitstream.append(0)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print("Reconstructing bit-shifted bytestreams...")</span></span>
<span class="line"><span>            byte_offsets = []</span></span>
<span class="line"><span>            for i in range(8):</span></span>
<span class="line"><span>                shifted_bytestream = []</span></span>
<span class="line"><span>                for j in range(i, len(bitstream)-7, 8):</span></span>
<span class="line"><span>                    val = 0</span></span>
<span class="line"><span>                    for k in range(8):</span></span>
<span class="line"><span>                        val |= bitstream[j+k] &#x3C;&#x3C; k</span></span>
<span class="line"><span>                    shifted_bytestream.append(val)</span></span>
<span class="line"><span>                byte_offsets.append(bytes(shifted_bytestream))</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # bit wrangling sanity checks</span></span>
<span class="line"><span>            assert(byte_offsets[0] == idat)</span></span>
<span class="line"><span>            assert(byte_offsets[1] != idat)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print("Scanning for viable parses...")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            # prefix the stream with 32k bytes so backrefs can work</span></span>
<span class="line"><span>            prefix_length = 0x8000</span></span>
<span class="line"><span>            prefix = b"\\x00" + (prefix_length).to_bytes(2, "little") + (prefix_length ^ 0xffff).to_bytes(2, "little") + b"\\x00" * prefix_length</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            for i in range(len(idat)):</span></span>
<span class="line"><span>                truncated = byte_offsets[i%8][i//8:]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                # only bother looking if it's (maybe) the start of a non-final adaptive huffman coded block</span></span>
<span class="line"><span>                if truncated[0]&#x26;7 != 0b100:</span></span>
<span class="line"><span>                    continue</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                d = zlib.decompressobj(wbits=-15)</span></span>
<span class="line"><span>                try:</span></span>
<span class="line"><span>                    decompressed = d.decompress(prefix+truncated) + d.flush(zlib.Z_FINISH)</span></span>
<span class="line"><span>                    decompressed = decompressed[prefix_length:] # remove leading padding</span></span>
<span class="line"><span>                    if d.eof and d.unused_data in [b"", b"\\x00"]: # there might be a null byte if we added too many padding bits</span></span>
<span class="line"><span>                        print(f"Found viable parse at bit offset {i}!")</span></span>
<span class="line"><span>                        # XXX: maybe there could be false positives and we should keep looking?</span></span>
<span class="line"><span>                        break</span></span>
<span class="line"><span>                    else:</span></span>
<span class="line"><span>                        print(f"Parsed until the end of a zlib stream, but there was still {len(d.unused_data)} bytes of remaining data. Skipping.")</span></span>
<span class="line"><span>                except zlib.error as e: # this will happen almost every time</span></span>
<span class="line"><span>                    pass</span></span>
<span class="line"><span>            else:</span></span>
<span class="line"><span>                print("Failed to find viable parse!")</span></span>
<span class="line"><span>                raise Exception("Failed to find viable parse!")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print("Generating output PNG...")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            output_path = os.path.join(tempfile.gettempdir(), 'restored.png')</span></span>
<span class="line"><span>            with open(output_path, "wb") as out:</span></span>
<span class="line"><span>                out.write(PNG_MAGIC)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                ihdr = b""</span></span>
<span class="line"><span>                ihdr += orig_width.to_bytes(4, "big")</span></span>
<span class="line"><span>                ihdr += orig_height.to_bytes(4, "big")</span></span>
<span class="line"><span>                ihdr += (8).to_bytes(1, "big") # bitdepth</span></span>
<span class="line"><span>                if rgb_alpha:</span></span>
<span class="line"><span>                    ihdr += (6).to_bytes(1, "big") # true colour with alpha</span></span>
<span class="line"><span>                else:</span></span>
<span class="line"><span>                    ihdr += (2).to_bytes(1, "big") # true colour</span></span>
<span class="line"><span>                ihdr += (0).to_bytes(1, "big") # compression method</span></span>
<span class="line"><span>                ihdr += (0).to_bytes(1, "big") # filter method</span></span>
<span class="line"><span>                ihdr += (0).to_bytes(1, "big") # interlace method</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                self.pack_png_chunk(out, b"IHDR", ihdr)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                # fill missing data with solid magenta</span></span>
<span class="line"><span>                if rgb_alpha:</span></span>
<span class="line"><span>                    reconstructed_idat = bytearray((b"\\x00" + b"\\xff\\x00\\xff\\xff" * orig_width) * orig_height)</span></span>
<span class="line"><span>                else:</span></span>
<span class="line"><span>                    reconstructed_idat = bytearray((b"\\x00" + b"\\xff\\x00\\xff" * orig_width) * orig_height)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                # paste in the data we decompressed</span></span>
<span class="line"><span>                reconstructed_idat[-len(decompressed):] = decompressed</span></span>
<span class="line"><span></span></span>
<span class="line"><span>                self.pack_png_chunk(out, b"IDAT", zlib.compress(reconstructed_idat))</span></span>
<span class="line"><span>                self.pack_png_chunk(out, b"IEND", b"")</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            print("Done!")</span></span>
<span class="line"><span>            return output_path</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Create an instance of the Acropalypse class</span></span>
<span class="line"><span>acropalypse = Acropalypse()</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Reconstruct the image using the correct resolution of 1920x1080</span></span>
<span class="line"><span>output_image_path = acropalypse.reconstruct_image('cm.png', 1920, 1080, True) // change to your input image file name</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre><span class="language transition-opacity duration-300 absolute top-3 right-3 text-sm text-muted-foreground select-none">plaintext</span><button class="copy transition-opacity duration-300 opacity-0 absolute top-3 right-3 text-muted-foreground p-1 box-content border border-border rounded bg-primary-foreground" data-code="import zlib
import io
import struct
import tempfile
import os

class Acropalypse():
    def parse_png_chunk(self, stream):
        size = int.from_bytes(stream.read(4), &#x22;big&#x22;)
        ctype = stream.read(4)
        body = stream.read(size)
        csum = int.from_bytes(stream.read(4), &#x22;big&#x22;)
        assert(zlib.crc32(ctype + body) == csum)
        return ctype, body

    def pack_png_chunk(self, stream, name, body):
        stream.write(len(body).to_bytes(4, &#x22;big&#x22;))
        stream.write(name)
        stream.write(body)
        crc = zlib.crc32(body, zlib.crc32(name))
        stream.write(crc.to_bytes(4, &#x22;big&#x22;))
        
    def reconstruct_image(self, cropped_image_file, img_width, img_height, rgb_alpha):
        PNG_MAGIC = b&#x22;\\x89PNG\\r\\n\\x1a\\n&#x22;

        orig_width = img_width
        orig_height = img_height

        with open(cropped_image_file, &#x22;rb&#x22;) as f_in:
            magic = f_in.read(len(PNG_MAGIC))
            assert magic == PNG_MAGIC

            # find end of cropped PNG
            while True:
                ctype, body = self.parse_png_chunk(f_in)
                if ctype == b&#x22;IEND&#x22;:
                    break

            # grab the trailing data
            trailer = f_in.read()
            
            print(f&#x22;Found {len(trailer)} trailing bytes!&#x22;)

            # find the start of the next idat chunk
            try:
                next_idat = trailer.index(b&#x22;IDAT&#x22;, 12)
            except ValueError:
                raise Exception(&#x22;No trailing IDATs found!&#x22;)

            # skip first 12 bytes in case they were part of a chunk boundary
            idat = trailer[12:next_idat-8] # last 8 bytes are crc32, next chunk len

            stream = io.BytesIO(trailer[next_idat-4:])

            while True:
                ctype, body = self.parse_png_chunk(stream)
                if ctype == b&#x22;IDAT&#x22;:
                    idat += body
                elif ctype == b&#x22;IEND&#x22;:
                    break
                else:
                    raise Exception(&#x22;Unexpected chunk type: &#x22; + repr(ctype))

            idat = idat[:-4] # slice off the adler32

            print(f&#x22;Extracted {len(idat)} bytes of idat!&#x22;)

            print(&#x22;Building bitstream...&#x22;)
            bitstream = []
            for byte in idat:
                for bit in range(8):
                    bitstream.append((byte >> bit) &#x26; 1)

            # add some padding so we don&#x27;t lose any bits
            for _ in range(7):
                bitstream.append(0)

            print(&#x22;Reconstructing bit-shifted bytestreams...&#x22;)
            byte_offsets = []
            for i in range(8):
                shifted_bytestream = []
                for j in range(i, len(bitstream)-7, 8):
                    val = 0
                    for k in range(8):
                        val |= bitstream[j+k] << k
                    shifted_bytestream.append(val)
                byte_offsets.append(bytes(shifted_bytestream))

            # bit wrangling sanity checks
            assert(byte_offsets[0] == idat)
            assert(byte_offsets[1] != idat)

            print(&#x22;Scanning for viable parses...&#x22;)

            # prefix the stream with 32k bytes so backrefs can work
            prefix_length = 0x8000
            prefix = b&#x22;\\x00&#x22; + (prefix_length).to_bytes(2, &#x22;little&#x22;) + (prefix_length ^ 0xffff).to_bytes(2, &#x22;little&#x22;) + b&#x22;\\x00&#x22; * prefix_length

            for i in range(len(idat)):
                truncated = byte_offsets[i%8][i//8:]

                # only bother looking if it&#x27;s (maybe) the start of a non-final adaptive huffman coded block
                if truncated[0]&#x26;7 != 0b100:
                    continue

                d = zlib.decompressobj(wbits=-15)
                try:
                    decompressed = d.decompress(prefix+truncated) + d.flush(zlib.Z_FINISH)
                    decompressed = decompressed[prefix_length:] # remove leading padding
                    if d.eof and d.unused_data in [b&#x22;&#x22;, b&#x22;\\x00&#x22;]: # there might be a null byte if we added too many padding bits
                        print(f&#x22;Found viable parse at bit offset {i}!&#x22;)
                        # XXX: maybe there could be false positives and we should keep looking?
                        break
                    else:
                        print(f&#x22;Parsed until the end of a zlib stream, but there was still {len(d.unused_data)} bytes of remaining data. Skipping.&#x22;)
                except zlib.error as e: # this will happen almost every time
                    pass
            else:
                print(&#x22;Failed to find viable parse!&#x22;)
                raise Exception(&#x22;Failed to find viable parse!&#x22;)

            print(&#x22;Generating output PNG...&#x22;)

            output_path = os.path.join(tempfile.gettempdir(), &#x27;restored.png&#x27;)
            with open(output_path, &#x22;wb&#x22;) as out:
                out.write(PNG_MAGIC)

                ihdr = b&#x22;&#x22;
                ihdr += orig_width.to_bytes(4, &#x22;big&#x22;)
                ihdr += orig_height.to_bytes(4, &#x22;big&#x22;)
                ihdr += (8).to_bytes(1, &#x22;big&#x22;) # bitdepth
                if rgb_alpha:
                    ihdr += (6).to_bytes(1, &#x22;big&#x22;) # true colour with alpha
                else:
                    ihdr += (2).to_bytes(1, &#x22;big&#x22;) # true colour
                ihdr += (0).to_bytes(1, &#x22;big&#x22;) # compression method
                ihdr += (0).to_bytes(1, &#x22;big&#x22;) # filter method
                ihdr += (0).to_bytes(1, &#x22;big&#x22;) # interlace method

                self.pack_png_chunk(out, b&#x22;IHDR&#x22;, ihdr)

                # fill missing data with solid magenta
                if rgb_alpha:
                    reconstructed_idat = bytearray((b&#x22;\\x00&#x22; + b&#x22;\\xff\\x00\\xff\\xff&#x22; * orig_width) * orig_height)
                else:
                    reconstructed_idat = bytearray((b&#x22;\\x00&#x22; + b&#x22;\\xff\\x00\\xff&#x22; * orig_width) * orig_height)

                # paste in the data we decompressed
                reconstructed_idat[-len(decompressed):] = decompressed

                self.pack_png_chunk(out, b&#x22;IDAT&#x22;, zlib.compress(reconstructed_idat))
                self.pack_png_chunk(out, b&#x22;IEND&#x22;, b&#x22;&#x22;)

            print(&#x22;Done!&#x22;)
            return output_path

# Create an instance of the Acropalypse class
acropalypse = Acropalypse()

# Reconstruct the image using the correct resolution of 1920x1080
output_image_path = acropalypse.reconstruct_image(&#x27;cm.png&#x27;, 1920, 1080, True) // change to your input image file name

" onclick="
          navigator.clipboard.writeText(this.dataset.code);
          this.classList.add(&#x27;copied&#x27;);
          setTimeout(() => this.classList.remove(&#x27;copied&#x27;), 2000)
        "><div class="ready"><svg class="size-5"><use href="/icons/code.svg#mingcute-clipboard-line"></use></svg></div><div class="success hidden"><svg class="size-5"><use href="/icons/code.svg#mingcute-file-check-line"></use></svg></div></button></div>
<p>References: <a href="https://youtu.be/R866SnJoKQg?si=rby5gJoYa2s9zR4N" rel="nofollow, noopener, noreferrer" target="_blank">https://youtu.be/R866SnJoKQg?si=rby5gJoYa2s9zR4N<span> ↗</span></a></p>
<ol start="3">
<li>Retrieve the recovered full image from the specified output directory: /tmp folder
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./files/restored.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"></li>
<li>Login to flickr with the credentials obtained from the recovered image</li>
</ol>
<div class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><pre><code><span class="line"><span>cybersteal6969@gmail.com</span></span>
<span class="line"><span>sh8UPt-S"Cp-6i+</span></span>
<span class="line"><span></span></span></code></pre><span class="language transition-opacity duration-300 absolute top-3 right-3 text-sm text-muted-foreground select-none">plaintext</span><button class="copy transition-opacity duration-300 opacity-0 absolute top-3 right-3 text-muted-foreground p-1 box-content border border-border rounded bg-primary-foreground" data-code="cybersteal6969@gmail.com
sh8UPt-S&#x22;Cp-6i+
" onclick="
          navigator.clipboard.writeText(this.dataset.code);
          this.classList.add(&#x27;copied&#x27;);
          setTimeout(() => this.classList.remove(&#x27;copied&#x27;), 2000)
        "><div class="ready"><svg class="size-5"><use href="/icons/code.svg#mingcute-clipboard-line"></use></svg></div><div class="success hidden"><svg class="size-5"><use href="/icons/code.svg#mingcute-file-check-line"></use></svg></div></button></div>
<p><img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/login.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
5. Browse through cybersteal6969’s profile, we found two videos, flag1 and flag2<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/cyberstealprofiile.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
6. From the video, we analyse the morse code, given “NO FLAG FOR YOU TRY SOMETHING ELSE”
Morse Code Analyser: <a href="https://morsecode.world/international/decoder/audio-decoder-adaptive.html" rel="nofollow, noopener, noreferrer" target="_blank">https://morsecode.world/international/decoder/audio-decoder-adaptive.html<span> ↗</span></a>
7. From the videos, we know that, it was posted by info stealer6969, shared to cybersteal6969, two of them are communicating<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/infostealerposted.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
8. Enter info stealer6969 profile, we found another video, named flag, analyse the morse code, we get “GOODJOBG3TT1NGH3R3”, this is the first decoy flag<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/infostealervid.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
9. Keep browsing, we found that info stealer6969 uploaded bunch of pictures<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/infopic.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
10. These pictures containing secret info in their metadata
11. Using exiftool, we found that cat.jpg directs us to <a href="https://cyberxstupid.blogspot.com/2024/12/blog-post.html" rel="nofollow, noopener, noreferrer" target="_blank">https://cyberxstupid.blogspot.com/2024/12/blog-post.html<span> ↗</span></a>, shown at comment section<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./files/pictures/cat.jpg&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/exifcat.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
12. Randomly clicking through the site, we found the second decoy flag CyberX{c4t_m0us3_g4m3_34sy}<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/first.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
13. Here we need to use Wayback Mahcine, archive.org, to track the past version of the site.<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/wayback.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"><br>
14. Under the same link but in past version, we obtain the final flag CyberX{c4t_m0us3_pl4y_m4d3_34s13r}<br>
<img __ASTRO_IMAGE_="{&#x22;src&#x22;:&#x22;./img/waybackflag.png&#x22;,&#x22;alt&#x22;:&#x22;&#x22;,&#x22;index&#x22;:0}"></p>`),N={title:"UTM CyberX Internal CTF 2024",publishDate:"2024-12-27T00:00:00.000Z",description:"Writeups for UTM CyberX Internal CTF 2024",tags:["CTF","Forensics"],heroImage:{src:"./cyberx.png",color:"#bababa"},language:"English",minutesRead:"5 min read"},C="C:/Users/gr1d/Documents/gr1d-init/gr1d-init.github.io/src/content/post/cyberxctf2024/index.md",O=void 0;function D(){return`
## Forensics
---

## Apocalypse

![](./img/question.png)  
### Description
Notorious hacker CyberSteal6969 has struck again, this time targeting CyberX, stealing a highly confidential flag. Our team managed to seize his personal computer, but the system was wiped clean, except for a single, suspicious image left behind.

Reports suggest CyberSteal6969 may have been communicating with his counterpart using morse code from video. But leave no stone unturned. Can you uncover the secrets within and retrieve the stolen flag?

---
#### Goals
1. Use pngchecker to check the status of the given image, obtained ERROR:"additional data after IEND chunk", which is after the cropped image
2. Use Acropalypse-Multi-Tool to recover the full image
   https://www.youtube.com/watch?v=R866SnJoKQg
3. Login to flickr with the credentials given
4. Try to find some useful informations across profile
5. Grab the pictures and analyse the metadata
6. Use wayback machine to track past version across the sites
---
#### Steps
1. pngchecker analyse the image  
   ![](./img/pngchecker.png)  
2. Use the script to recover the full image
\`\`\`
import zlib
import io
import struct
import tempfile
import os

class Acropalypse():
    def parse_png_chunk(self, stream):
        size = int.from_bytes(stream.read(4), "big")
        ctype = stream.read(4)
        body = stream.read(size)
        csum = int.from_bytes(stream.read(4), "big")
        assert(zlib.crc32(ctype + body) == csum)
        return ctype, body

    def pack_png_chunk(self, stream, name, body):
        stream.write(len(body).to_bytes(4, "big"))
        stream.write(name)
        stream.write(body)
        crc = zlib.crc32(body, zlib.crc32(name))
        stream.write(crc.to_bytes(4, "big"))
        
    def reconstruct_image(self, cropped_image_file, img_width, img_height, rgb_alpha):
        PNG_MAGIC = b"\\x89PNG\\r\\n\\x1a\\n"

        orig_width = img_width
        orig_height = img_height

        with open(cropped_image_file, "rb") as f_in:
            magic = f_in.read(len(PNG_MAGIC))
            assert magic == PNG_MAGIC

            # find end of cropped PNG
            while True:
                ctype, body = self.parse_png_chunk(f_in)
                if ctype == b"IEND":
                    break

            # grab the trailing data
            trailer = f_in.read()
            
            print(f"Found {len(trailer)} trailing bytes!")

            # find the start of the next idat chunk
            try:
                next_idat = trailer.index(b"IDAT", 12)
            except ValueError:
                raise Exception("No trailing IDATs found!")

            # skip first 12 bytes in case they were part of a chunk boundary
            idat = trailer[12:next_idat-8] # last 8 bytes are crc32, next chunk len

            stream = io.BytesIO(trailer[next_idat-4:])

            while True:
                ctype, body = self.parse_png_chunk(stream)
                if ctype == b"IDAT":
                    idat += body
                elif ctype == b"IEND":
                    break
                else:
                    raise Exception("Unexpected chunk type: " + repr(ctype))

            idat = idat[:-4] # slice off the adler32

            print(f"Extracted {len(idat)} bytes of idat!")

            print("Building bitstream...")
            bitstream = []
            for byte in idat:
                for bit in range(8):
                    bitstream.append((byte >> bit) & 1)

            # add some padding so we don't lose any bits
            for _ in range(7):
                bitstream.append(0)

            print("Reconstructing bit-shifted bytestreams...")
            byte_offsets = []
            for i in range(8):
                shifted_bytestream = []
                for j in range(i, len(bitstream)-7, 8):
                    val = 0
                    for k in range(8):
                        val |= bitstream[j+k] << k
                    shifted_bytestream.append(val)
                byte_offsets.append(bytes(shifted_bytestream))

            # bit wrangling sanity checks
            assert(byte_offsets[0] == idat)
            assert(byte_offsets[1] != idat)

            print("Scanning for viable parses...")

            # prefix the stream with 32k bytes so backrefs can work
            prefix_length = 0x8000
            prefix = b"\\x00" + (prefix_length).to_bytes(2, "little") + (prefix_length ^ 0xffff).to_bytes(2, "little") + b"\\x00" * prefix_length

            for i in range(len(idat)):
                truncated = byte_offsets[i%8][i//8:]

                # only bother looking if it's (maybe) the start of a non-final adaptive huffman coded block
                if truncated[0]&7 != 0b100:
                    continue

                d = zlib.decompressobj(wbits=-15)
                try:
                    decompressed = d.decompress(prefix+truncated) + d.flush(zlib.Z_FINISH)
                    decompressed = decompressed[prefix_length:] # remove leading padding
                    if d.eof and d.unused_data in [b"", b"\\x00"]: # there might be a null byte if we added too many padding bits
                        print(f"Found viable parse at bit offset {i}!")
                        # XXX: maybe there could be false positives and we should keep looking?
                        break
                    else:
                        print(f"Parsed until the end of a zlib stream, but there was still {len(d.unused_data)} bytes of remaining data. Skipping.")
                except zlib.error as e: # this will happen almost every time
                    pass
            else:
                print("Failed to find viable parse!")
                raise Exception("Failed to find viable parse!")

            print("Generating output PNG...")

            output_path = os.path.join(tempfile.gettempdir(), 'restored.png')
            with open(output_path, "wb") as out:
                out.write(PNG_MAGIC)

                ihdr = b""
                ihdr += orig_width.to_bytes(4, "big")
                ihdr += orig_height.to_bytes(4, "big")
                ihdr += (8).to_bytes(1, "big") # bitdepth
                if rgb_alpha:
                    ihdr += (6).to_bytes(1, "big") # true colour with alpha
                else:
                    ihdr += (2).to_bytes(1, "big") # true colour
                ihdr += (0).to_bytes(1, "big") # compression method
                ihdr += (0).to_bytes(1, "big") # filter method
                ihdr += (0).to_bytes(1, "big") # interlace method

                self.pack_png_chunk(out, b"IHDR", ihdr)

                # fill missing data with solid magenta
                if rgb_alpha:
                    reconstructed_idat = bytearray((b"\\x00" + b"\\xff\\x00\\xff\\xff" * orig_width) * orig_height)
                else:
                    reconstructed_idat = bytearray((b"\\x00" + b"\\xff\\x00\\xff" * orig_width) * orig_height)

                # paste in the data we decompressed
                reconstructed_idat[-len(decompressed):] = decompressed

                self.pack_png_chunk(out, b"IDAT", zlib.compress(reconstructed_idat))
                self.pack_png_chunk(out, b"IEND", b"")

            print("Done!")
            return output_path

# Create an instance of the Acropalypse class
acropalypse = Acropalypse()

# Reconstruct the image using the correct resolution of 1920x1080
output_image_path = acropalypse.reconstruct_image('cm.png', 1920, 1080, True) // change to your input image file name

\`\`\`
References: https://youtu.be/R866SnJoKQg?si=rby5gJoYa2s9zR4N

3. Retrieve the recovered full image from the specified output directory: /tmp folder
![](./files/restored.png)  
4. Login to flickr with the credentials obtained from the recovered image  
\`\`\`
cybersteal6969@gmail.com
sh8UPt-S"Cp-6i+
\`\`\`
 ![](./img/login.png)  
5. Browse through cybersteal6969's profile, we found two videos, flag1 and flag2  
![](./img/cyberstealprofiile.png)  
6. From the video, we analyse the morse code, given "NO FLAG FOR YOU TRY SOMETHING ELSE"
Morse Code Analyser: https://morsecode.world/international/decoder/audio-decoder-adaptive.html
7. From the videos, we know that, it was posted by info stealer6969, shared to cybersteal6969, two of them are communicating  
   ![](./img/infostealerposted.png)  
8. Enter info stealer6969 profile, we found another video, named flag, analyse the morse code, we get "GOODJOBG3TT1NGH3R3", this is the first decoy flag  
![](./img/infostealervid.png)  
9. Keep browsing, we found that info stealer6969 uploaded bunch of pictures  
![](./img/infopic.png)  
10. These pictures containing secret info in their metadata
11. Using exiftool, we found that cat.jpg directs us to https://cyberxstupid.blogspot.com/2024/12/blog-post.html, shown at comment section  
![](./files/pictures/cat.jpg)  
![](./img/exifcat.png)  
12. Randomly clicking through the site, we found the second decoy flag CyberX{c4t_m0us3_g4m3_34sy}  
![](./img/first.png)  
13. Here we need to use Wayback Mahcine, archive.org, to track the past version of the site.  
![](./img/wayback.png)  
14. Under the same link but in past version, we obtain the final flag CyberX{c4t_m0us3_pl4y_m4d3_34s13r}  
![](./img/waybackflag.png)`}function F(){return c}function U(){return[{depth:2,slug:"forensics",text:"Forensics"},{depth:2,slug:"apocalypse",text:"Apocalypse"},{depth:3,slug:"description",text:"Description"},{depth:4,slug:"goals",text:"Goals"},{depth:4,slug:"steps",text:"Steps"}]}const J=g((r,p,a)=>{const{layout:e,...n}=N;return n.file=C,n.url=O,h`${f()}${b(c)}`});export{J as Content,F as compiledContent,J as default,C as file,N as frontmatter,U as getHeadings,D as rawContent,O as url};
